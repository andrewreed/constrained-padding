{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import altair as alt\n",
    "from copy import copy\n",
    "\n",
    "%run implementations.ipynb\n",
    "%run utilities.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sizes = pd.read_csv('npmpackages/npm_no_scope_full_stats_nonzero_downloads.csv', header=None)\n",
    "sizes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = pd.read_csv('unsplash/lite/unsplash_lite.csv', header=None)\n",
    "sizes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list = sizes[1].tolist()\n",
    "\n",
    "size_counts = defaultdict(int)\n",
    "\n",
    "for size in size_list:\n",
    "    size_counts[size] += 1\n",
    "    \n",
    "uniq_sizes = sorted(list(size_counts.keys()))\n",
    "\n",
    "c_list = [1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09, 1.1]\n",
    "\n",
    "runtimes = []\n",
    "\n",
    "for c in c_list:\n",
    "    p_alpaca_no_metrics_time = 0.\n",
    "    min_mi_per_obj_time = 0.\n",
    "    pure_maxl_time = 0.\n",
    "    \n",
    "    for i in range(10):\n",
    "        start = time.time()\n",
    "        p_alpaca_results = p_alpaca_no_metrics(sizes, c)\n",
    "        stop  = time.time()\n",
    "        p_alpaca_no_metrics_time += stop - start\n",
    "        \n",
    "    p_alpaca_no_metrics_time *= .1\n",
    "    \n",
    "    for i in range(10):\n",
    "        start = time.time()\n",
    "\n",
    "        partition, dyn_solution = opt_partition_MI(sizes, c)\n",
    "\n",
    "        size_map = {}    \n",
    "        current_block = 0\n",
    "        current_ceiling = partition[current_block][1]\n",
    "\n",
    "        for size in uniq_sizes:\n",
    "            if size > current_ceiling:\n",
    "                current_block += 1\n",
    "                current_ceiling = partition[current_block][1]\n",
    "            size_map[size] = current_ceiling\n",
    "    \n",
    "        stop = time.time()\n",
    "        \n",
    "        min_mi_per_obj_time += stop - start\n",
    "        \n",
    "    min_mi_per_obj_time *= .1\n",
    "    \n",
    "    for i in range(10):\n",
    "        start = time.time()\n",
    "\n",
    "        size_map = pureMaxL(sizes, c)\n",
    "    \n",
    "        stop = time.time()\n",
    "        \n",
    "        pure_maxl_time += stop - start\n",
    "        \n",
    "    pure_maxl_time *= .1\n",
    "\n",
    "    start = time.time()\n",
    "    min_mi_per_req_results = BlahutArimoto(sizes, c, max_itr=10000000, eps=5e-3)\n",
    "    stop = time.time()\n",
    "    \n",
    "    min_mi_per_req_time = stop - start\n",
    "    \n",
    "    runtimes.append((\"P-ALPaCA\", c, p_alpaca_no_metrics_time))\n",
    "    runtimes.append((\"MI_per_object\", c, min_mi_per_obj_time))\n",
    "    runtimes.append((\"Pure_MaxL\", c, pure_maxl_time))\n",
    "    runtimes.append((\"MI_per_request\", c, min_mi_per_req_time))\n",
    "    \n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtimes = pd.DataFrame(runtimes, columns =['Method', 'c', 'Runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "size_list = sizes[1].tolist()\n",
    "\n",
    "size_counts = defaultdict(int)\n",
    "\n",
    "for size in size_list:\n",
    "    size_counts[size] += 1\n",
    "    \n",
    "uniq_sizes = sorted(list(size_counts.keys()))\n",
    "\n",
    "c_list = [1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09, 1.1]\n",
    "\n",
    "runtimes = []\n",
    "\n",
    "for c in c_list:\n",
    "    \n",
    "    time_samples = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        start = time.time()\n",
    "        p_alpaca_results = p_alpaca_no_metrics(sizes, c)\n",
    "        stop  = time.time()\n",
    "        time_samples.append(stop - start)\n",
    "        \n",
    "    p_alpaca_no_metrics_time = statistics.mean(time_samples)\n",
    "    p_alpaca_no_metrics_rel_std_dev = 100 * (statistics.pstdev(time_samples) / p_alpaca_no_metrics_time)\n",
    "    \n",
    "    time_samples = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        start = time.time()\n",
    "\n",
    "        partition, dyn_solution = opt_partition_MI(sizes, c)\n",
    "\n",
    "        size_map = {}    \n",
    "        current_block = 0\n",
    "        current_ceiling = partition[current_block][1]\n",
    "\n",
    "        for size in uniq_sizes:\n",
    "            if size > current_ceiling:\n",
    "                current_block += 1\n",
    "                current_ceiling = partition[current_block][1]\n",
    "            size_map[size] = current_ceiling\n",
    "    \n",
    "        stop = time.time()\n",
    "        \n",
    "        time_samples.append(stop - start)\n",
    "        \n",
    "    min_mi_per_obj_time = statistics.mean(time_samples)\n",
    "    min_mi_per_obj_rel_std_dev = 100 * (statistics.pstdev(time_samples) / min_mi_per_obj_time)\n",
    "    \n",
    "    time_samples = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        start = time.time()\n",
    "\n",
    "        size_map = pureMaxL(sizes, c)\n",
    "    \n",
    "        stop = time.time()\n",
    "        \n",
    "        time_samples.append(stop - start)\n",
    "        \n",
    "    pure_maxl_time = statistics.mean(time_samples)\n",
    "    pure_maxl_rel_std_dev = 100 * (statistics.pstdev(time_samples) / pure_maxl_time)\n",
    "    \n",
    "    time_samples = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        start = time.time()\n",
    "        min_mi_per_req_results = BlahutArimoto(sizes, c, max_itr=10000000, eps=5e-4)\n",
    "        stop = time.time()\n",
    "    \n",
    "        time_samples.append(stop - start)\n",
    "    print(str(c) + '\\t' + str(min_mi_per_req_results[2]))    \n",
    "    min_mi_per_req_time = statistics.mean(time_samples)\n",
    "    min_mi_per_req_rel_std_dev = 100 * (statistics.pstdev(time_samples) / min_mi_per_req_time)\n",
    "    \n",
    "    runtimes.append((\"P-ALPaCA\", c, p_alpaca_no_metrics_time, p_alpaca_no_metrics_rel_std_dev))\n",
    "    runtimes.append((\"MI_per_object\", c, min_mi_per_obj_time, min_mi_per_obj_rel_std_dev))\n",
    "    runtimes.append((\"Pure_MaxL\", c, pure_maxl_time, pure_maxl_rel_std_dev))\n",
    "    runtimes.append((\"MI_per_request\", c, min_mi_per_req_time, min_mi_per_req_rel_std_dev))\n",
    "    \n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtimes = pd.DataFrame(runtimes, columns =['Method', 'c', 'Avg Runtime', 'Rel Std Dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_runtimes).mark_line().encode(\n",
    "    alt.X('c', scale=alt.Scale(domain=(1.01, 1.09))),\n",
    "    alt.Y('Avg Runtime', scale=alt.Scale(domain=(0, 3.5))),\n",
    "    color='Method',\n",
    "    strokeDash='Method',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtimes_temp = df_runtimes.loc[df_runtimes['Method'] != 'MI_per_request', ['Method', 'c', 'Runtime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_runtimes_temp).mark_line().encode(\n",
    "    alt.X('c', scale=alt.Scale(domain=(1.01, 1.09))),\n",
    "    alt.Y('Runtime', scale=alt.Scale(domain=(0, .35))),\n",
    "    color='Method',\n",
    "    strokeDash='Method',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtimes.to_csv('evaluation/runtimes-unsplash_1-01_to_1-10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Print__ $\\LaTeX{}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtimes = pd.read_csv('evaluation/runtimes-unsplash_1-01_to_1-10.csv')\n",
    "df_runtimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"MI_per_request\", \"MI_per_object\", \"P-ALPaCA\", \"Pure_MaxL\"]\n",
    "legend = {\n",
    "          \"MI_per_request\": \"[line width=1pt, densely dotted, curvecolor]\", \n",
    "          \"MI_per_object\": \"[line width=1pt, dash pattern=on 1pt off 3pt on 3pt off 3pt, curvecolor]\", \n",
    "          \"P-ALPaCA\": \"[line width=1pt, solid, curvecolor]\", \n",
    "          \"Pure_MaxL\": \"[line width=1.5pt, dash pattern=on 1pt off 3pt on 3pt off 3pt, black]\"\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    df_method_temp = df_runtimes.loc[df_runtimes['Method'] == method, ['c', 'Avg Runtime']]\n",
    "    print(\"\\\\addplot \" + legend[method])\n",
    "    print(\"table {%\")\n",
    "    for row in df_method_temp.itertuples():\n",
    "        print(str(row.c) + ' ' + str(row[2]))        \n",
    "    print(\"};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = pd.read_csv('npmpackages/npm_no_scope_full_stats_nonzero_downloads.csv', header=None)\n",
    "total_downloads = sizes[2].sum()\n",
    "\n",
    "sorted_sizes = sizes.sort_values(by=[2], ascending=False)\n",
    "update_names = sorted_sizes.head(10)[0].tolist()\n",
    "print(update_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = pd.read_csv('unsplash/lite/unsplash_lite.csv', header=None)\n",
    "total_downloads = sizes[2].sum()\n",
    "\n",
    "sorted_sizes = sizes.sort_values(by=[2], ascending=False)\n",
    "update_names = sorted_sizes.head(10)[0].tolist()\n",
    "print(update_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1.1\n",
    "growth = 1.25\n",
    "\n",
    "start = time.time()\n",
    "i_max, cndl_idxs, p_ji, p_i, s, orig_p_j_dict, size_to_i, this_MI, max_L = BlahutArimoto_init(sizes, c, max_itr=10000000, eps=5e-3)\n",
    "stop = time.time()\n",
    "print(str(stop - start))\n",
    "print(this_MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o_id in update_names:\n",
    "    p_j_dict = copy(orig_p_j_dict)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    o_index = sizes.index[sizes[0].values == o_id][0]\n",
    "    o_old_size = sizes.loc[o_index][1]\n",
    "    o_old_prob = sizes.loc[o_index][2] / total_downloads\n",
    "\n",
    "    o_new_size = math.ceil(o_old_size * growth)\n",
    "\n",
    "    this_i = size_to_i[o_old_size]\n",
    "    i_num_cndls = i_max[this_i] - this_i + 1\n",
    "    i_idx = cndl_idxs[this_i]\n",
    "        \n",
    "    for offset in range(i_num_cndls):\n",
    "        this_j = this_i + offset\n",
    "        j_size = s[this_j]\n",
    "        idx = i_idx + offset\n",
    "        prob = p_ji[idx]\n",
    "        p_j_dict[j_size] -= prob*o_old_prob\n",
    "    \n",
    "    all_sizes = sorted(p_j_dict.keys())\n",
    "    feasible_sizes = set()\n",
    "    feasible_sizes.add(o_new_size)\n",
    "    for size in all_sizes:\n",
    "        if size < o_new_size:\n",
    "            continue\n",
    "        if c*o_new_size < size:\n",
    "            break\n",
    "        feasible_sizes.add(size)\n",
    "    \n",
    "    num_feasible = len(feasible_sizes)\n",
    "    equal_share = o_old_prob / num_feasible\n",
    "\n",
    "    for f_size in feasible_sizes:\n",
    "        p_j_dict[f_size] += equal_share\n",
    "\n",
    "    sizes.at[o_index, 1] = o_new_size\n",
    "   \n",
    "    DISCARD_i_max, DISCARD_cndl_idxs, DISCARD_p_ji, DISCARD_p_i, DISCARD_s, DISCARD_p_j_dict, DISCARD_size_to_i, DISCARD_this_MI, DISCARD_max_L = BlahutArimoto_incr(sizes, c, p_j_dict, max_itr=10000000, eps=5e-3)\n",
    "\n",
    "    stop = time.time()\n",
    "    print(stop - start)\n",
    "    \n",
    "    sizes.at[o_index, 1] = o_old_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
