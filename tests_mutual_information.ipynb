{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "%run implementations.ipynb\n",
    "%run utilities.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sizes = pd.read_csv('npmpackages/npm_no_scope_full_stats_nonzero_downloads.csv', header=None)\n",
    "sizes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = pd.read_csv('unsplash/lite/unsplash_lite.csv', header=None)\n",
    "sizes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information & MaxL Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list = sizes[1].tolist()\n",
    "\n",
    "size_counts = defaultdict(int)\n",
    "\n",
    "for size in size_list:\n",
    "    size_counts[size] += 1\n",
    "    \n",
    "uniq_sizes = sorted(list(size_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_list = [1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09, 1.1]\n",
    "\n",
    "MI_and_MaxL = []\n",
    "\n",
    "for c in c_list:\n",
    "    # MI_per_request\n",
    "    MI, MaxL, itr = BlahutArimoto(sizes, c, max_itr=10000000, eps=1e-2)\n",
    "    MI_and_MaxL.append((\"MI_per_request\", c, MI, math.log2(MaxL)))\n",
    "    print(str(c) + '\\t' + \"MI_per_request\")\n",
    "    \n",
    "    # P-ALPaCA\n",
    "    MI, MaxL = p_alpaca(sizes, c)\n",
    "    MI_and_MaxL.append((\"P-ALPaCA\", c, MI, math.log2(MaxL)))\n",
    "    print(str(c) + '\\t' + \"P-ALPaCA\")\n",
    "    \n",
    "    # MI_per_object\n",
    "    partition, dyn_solution = opt_partition_MI(sizes, c)\n",
    "\n",
    "    size_map = {}    \n",
    "    current_block = 0\n",
    "    current_ceiling = partition[current_block][1]\n",
    "\n",
    "    for size in uniq_sizes:\n",
    "        if size > current_ceiling:\n",
    "            current_block += 1\n",
    "            current_ceiling = partition[current_block][1]\n",
    "        size_map[size] = current_ceiling\n",
    "\n",
    "    dyn_list = []\n",
    "\n",
    "    for row in sizes.itertuples(index=False):\n",
    "        dyn_size = size_map[row[1]]\n",
    "        dyn_list.append((row[0], dyn_size, row[2]))\n",
    "    \n",
    "    dyn_sizes = pd.DataFrame(dyn_list)\n",
    "    \n",
    "    MI, MaxL = calc_MI_and_MaxL_fixed(dyn_sizes)\n",
    "    MI_and_MaxL.append((\"MI_per_object\", c, MI, MaxL))\n",
    "    print(str(c) + '\\t' + \"MI_per_object\")    \n",
    "    \n",
    "    # Pure_MaxL\n",
    "    size_map = pureMaxL(sizes, c)    \n",
    "\n",
    "    dyn_list = []\n",
    "\n",
    "    for row in sizes.itertuples(index=False):\n",
    "        dyn_size = size_map[row[1]]\n",
    "        dyn_list.append((row[0], dyn_size, row[2]))\n",
    "    \n",
    "    dyn_sizes = pd.DataFrame(dyn_list)\n",
    "    \n",
    "    MI, MaxL = calc_MI_and_MaxL_fixed(dyn_sizes)\n",
    "    MI_and_MaxL.append((\"Pure_MaxL\", c, MI, MaxL))\n",
    "    print(str(c) + '\\t' + \"Pure_MaxL\")\n",
    "    \n",
    "    # D-ALPaCA\n",
    "    min_size = sizes[1].min()\n",
    "    bin_size = int(c*min_size) - min_size\n",
    "    \n",
    "    d_alpaca_list = []\n",
    "\n",
    "    for row in sizes.itertuples(index=False):\n",
    "        d_alpaca_size = getDALPaCA(row[1], bin_size)\n",
    "        d_alpaca_list.append((row[0], d_alpaca_size, row[2]))\n",
    "    \n",
    "    d_alpaca_sizes = pd.DataFrame(d_alpaca_list)\n",
    "    \n",
    "    MI, MaxL = calc_MI_and_MaxL_fixed(d_alpaca_sizes)\n",
    "    MI_and_MaxL.append((\"D-ALPaCA\", c, MI, MaxL))\n",
    "    print(str(c) + '\\t' + \"D-ALPaCA\")\n",
    "    \n",
    "# Padme\n",
    "padme_list = []\n",
    "\n",
    "max_overhead = 0.\n",
    "\n",
    "for row in sizes.itertuples(index=False):\n",
    "    padme_size = getPadme(row[1])\n",
    "    padme_list.append((row[0], padme_size, row[2]))\n",
    "    \n",
    "    overhead = padme_size / row[1]\n",
    "    if overhead > max_overhead:\n",
    "        max_overhead = overhead\n",
    "    \n",
    "padme_sizes = pd.DataFrame(padme_list)\n",
    "\n",
    "MI, MaxL = calc_MI_and_MaxL_fixed(padme_sizes)\n",
    "MI_and_MaxL.append((\"Padme\", max_overhead, MI, MaxL))\n",
    "print(str(max_overhead) + '\\t' + \"Padme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MI_and_MaxL = pd.DataFrame(MI_and_MaxL, columns =['Method', 'c', 'MI', 'MaxL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_MI_and_MaxL).mark_line().encode(\n",
    "    alt.X('MI', scale=alt.Scale(domain=(5.0, 13))),\n",
    "    alt.Y('MaxL', scale=alt.Scale(domain=(5.5, 14))),\n",
    "    color='Method',\n",
    "    strokeDash='Method',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MI_and_MaxL_temp = df_MI_and_MaxL.loc[df_MI_and_MaxL['Method'] != 'D-ALPaCA', ['Method', 'c', 'MI', 'MaxL']]\n",
    "\n",
    "alt.Chart(df_MI_and_MaxL_temp).mark_line().encode(\n",
    "    alt.X('c', scale=alt.Scale(domain=(1.01, 1.09))),\n",
    "    alt.Y('MI', scale=alt.Scale(domain=(5.0, 8.5))),\n",
    "    color='Method',\n",
    "    strokeDash='Method',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MI_and_MaxL.to_csv('evaluation/MI-and-MaxL-nodejs_1-01_to_1-10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Print__ $\\LaTeX{}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MI_and_MaxL = pd.read_csv('evaluation/MI-and-MaxL-unsplash_1-01_to_1-10.csv')\n",
    "df_MI_and_MaxL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"D-ALPaCA\", \"Pure_MaxL\", \"P-ALPaCA\", \"MI_per_object\", \"MI_per_request\"]\n",
    "legend = {\n",
    "          \"MI_per_request\": \"[style={fill=white},error bars/.cd, y dir=both, y explicit]\", \n",
    "          \"MI_per_object\": \"[black!100!white,fill=black!25!white,error bars/.cd, y dir=both, y explicit]\", \n",
    "          \"P-ALPaCA\": \"[black!100!white,fill=black!50!white,error bars/.cd, y dir=both, y explicit]\", \n",
    "          \"Pure_MaxL\": \"[black!100!white,fill=black!75!white,error bars/.cd, y dir=both, y explicit]\", \n",
    "          \"Padme\": \"[style={fill=white,postaction={pattern=north east lines}},error bars/.cd, y dir=both, y explicit]\", \n",
    "          \"D-ALPaCA\": \"[black!100!white,fill=black!100!white,error bars/.cd, y dir=both, y explicit]\"\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_method_temp = df_MI_and_MaxL.loc[df_MI_and_MaxL['Method'] == \"Padme\", ['c', 'MI', 'MaxL']]\n",
    "print(\"\\\\addplot\" + legend[\"Padme\"])\n",
    "print(\"coordinates {%\")\n",
    "print(\"(1.01, -0.01)\")\n",
    "print(\"(1.02, -0.01)\")\n",
    "#print(\"(1.03, -0.01)\")\n",
    "for row in df_method_temp.itertuples():\n",
    "    error = row.MaxL - row.MI\n",
    "    print(\"(1.03, \" + str(row.MI) + \") += (0,\" +str(error) + \")\")\n",
    "print(\"(1.04, -0.01)\")\n",
    "print(\"(1.05, -0.01)\")\n",
    "print(\"(1.06, -0.01)\")\n",
    "print(\"(1.07, -0.01)\")\n",
    "print(\"(1.08, -0.01)\")\n",
    "print(\"(1.09, -0.01)\")\n",
    "#for row in df_method_temp.itertuples():\n",
    "#    error = row.MaxL - row.MI\n",
    "#    print(\"(1.09, \" + str(row.MI) + \") += (0,\" +str(error) + \")\")\n",
    "print(\"(1.1, -0.01)\")\n",
    "print(\"};\")\n",
    "\n",
    "for method in methods:\n",
    "    df_method_temp = df_MI_and_MaxL.loc[df_MI_and_MaxL['Method'] == method, ['c', 'MI', 'MaxL']]\n",
    "    print(\"\\\\addplot\" + legend[method])\n",
    "    print(\"coordinates {%\")\n",
    "    for row in df_method_temp.itertuples():\n",
    "        error = row.MaxL - row.MI\n",
    "        print(\"(\"+str(row.c)+\", \"+str(row.MI)+\") += (0,\"+str(error)+\")\")        \n",
    "    print(\"};\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
