{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "%run implementations.ipynb\n",
    "%run utilities.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = pd.read_csv('npmpackages/npm_no_scope_full_stats_nonzero_downloads.csv', header=None)\n",
    "total_downloads = sizes[2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = pd.read_csv('unsplash/lite/unsplash_lite.csv', header=None)\n",
    "total_downloads = sizes[2].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list = sizes[1].tolist()\n",
    "\n",
    "size_counts = defaultdict(int)\n",
    "\n",
    "for size in size_list:\n",
    "    size_counts[size] += 1\n",
    "    \n",
    "uniq_sizes = sorted(list(size_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = [1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09, 1.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_overhead_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in c_list:\n",
    "    i_max, cndl_idxs, p_ji, p_i, s, orig_p_j_dict, size_to_i, this_MI, max_L = BlahutArimoto_init(sizes, c, max_itr=10000000, eps=5e-3)\n",
    "\n",
    "    max_overhead = 0.\n",
    "    avg_overhead = 0.\n",
    "    \n",
    "    for i in range(len(uniq_sizes)):\n",
    "        i_num_cndls = i_max[i] - i + 1\n",
    "        i_idx = cndl_idxs[i]\n",
    "        \n",
    "        for offset in range(i_num_cndls):\n",
    "            j = i + offset\n",
    "            idx = i_idx + offset\n",
    "            prob = p_ji[idx]\n",
    "            \n",
    "            overhead = s[j] / s[i]\n",
    "            if overhead > max_overhead and prob > 0.:\n",
    "                max_overhead = overhead\n",
    "        \n",
    "            avg_overhead += overhead * prob * p_i[i]\n",
    "            \n",
    "    avg_overhead_list.append((\"PRP\", c, avg_overhead))\n",
    "    print(avg_overhead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-ALPaCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in c_list:\n",
    "    i_max, cndl_idxs, p_ji, p_i, s, orig_p_j_dict, size_to_i, this_MI, max_L = p_alpaca_return_all(sizes, c)\n",
    "\n",
    "    max_overhead = 0.\n",
    "    avg_overhead = 0.\n",
    "    \n",
    "    for i in range(len(uniq_sizes)):\n",
    "        i_num_cndls = i_max[i] - i + 1\n",
    "        i_idx = cndl_idxs[i]\n",
    "        \n",
    "        for offset in range(i_num_cndls):\n",
    "            j = i + offset\n",
    "            idx = i_idx + offset\n",
    "            prob = p_ji[idx]\n",
    "            \n",
    "            overhead = s[j] / s[i]\n",
    "            if overhead > max_overhead and prob > 0.:\n",
    "                max_overhead = overhead\n",
    "        \n",
    "            avg_overhead += overhead * prob * p_i[i]\n",
    "            \n",
    "    avg_overhead_list.append((\"P-ALPaCA\", c, avg_overhead))\n",
    "    print(avg_overhead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in c_list:\n",
    "    partition, dyn_solution = opt_partition_MI(sizes, c)\n",
    "\n",
    "    size_map = {}    \n",
    "    current_block = 0\n",
    "    current_ceiling = partition[current_block][1]\n",
    "\n",
    "    for size in uniq_sizes:\n",
    "        if size > current_ceiling:\n",
    "            current_block += 1\n",
    "            current_ceiling = partition[current_block][1]\n",
    "        size_map[size] = current_ceiling\n",
    "\n",
    "    max_overhead = 0.\n",
    "    avg_overhead = 0.\n",
    "\n",
    "    for row in sizes.itertuples(index=False):\n",
    "        dyn_size = size_map[row[1]]\n",
    "    \n",
    "        overhead = dyn_size / row[1]\n",
    "        if overhead > max_overhead:\n",
    "            max_overhead = overhead\n",
    "        \n",
    "        avg_overhead += overhead * (row[2] / total_downloads)\n",
    "        \n",
    "    avg_overhead_list.append((\"POP\", c, avg_overhead))\n",
    "    print(avg_overhead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PwoD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in c_list:\n",
    "    size_map = pureMaxL(sizes, c)\n",
    "\n",
    "    max_overhead = 0.\n",
    "    avg_overhead = 0.\n",
    "\n",
    "    for row in sizes.itertuples(index=False):\n",
    "        dyn_size = size_map[row[1]]\n",
    "    \n",
    "        overhead = dyn_size / row[1]\n",
    "        if overhead > max_overhead:\n",
    "            max_overhead = overhead\n",
    "        \n",
    "        avg_overhead += overhead * (row[2] / total_downloads)\n",
    "        \n",
    "    avg_overhead_list.append((\"PwoD\", c, avg_overhead))\n",
    "    print(avg_overhead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D-ALPaCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in c_list:\n",
    "    min_size = sizes[1].min()\n",
    "    bin_size = int(c*min_size) - min_size\n",
    "    \n",
    "    d_alpaca_list = []\n",
    "\n",
    "    max_overhead = 0.\n",
    "    avg_overhead = 0.\n",
    "\n",
    "    for row in sizes.itertuples(index=False):\n",
    "        d_alpaca_size = getDALPaCA(row[1], bin_size)\n",
    "    \n",
    "        overhead = d_alpaca_size / row[1]\n",
    "        if overhead > max_overhead:\n",
    "            max_overhead = overhead\n",
    "        \n",
    "        avg_overhead += overhead * (row[2] / total_downloads)\n",
    "        \n",
    "    avg_overhead_list.append((\"D-ALPaCA\", c, avg_overhead))\n",
    "    print(avg_overhead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_overhead = 0.\n",
    "avg_overhead = 0.\n",
    "\n",
    "for row in sizes.itertuples(index=False):\n",
    "    padme_size = getPadme(row[1])\n",
    "    \n",
    "    overhead = padme_size / row[1]\n",
    "    if overhead > max_overhead:\n",
    "        max_overhead = overhead\n",
    "        \n",
    "    avg_overhead += overhead * (row[2] / total_downloads)\n",
    "    \n",
    "avg_overhead_list.append((\"Padme\", max_overhead, avg_overhead))\n",
    "print(avg_overhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_overhead = pd.DataFrame(avg_overhead_list, columns =['Method', 'c', 'Avg Overhead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_avg_overhead).mark_line().encode(\n",
    "    alt.X('c', scale=alt.Scale(domain=(1.01, 1.09))),\n",
    "    alt.Y('Avg Overhead', scale=alt.Scale(domain=(1.00, 1.05))),\n",
    "    color='Method',\n",
    "    strokeDash='Method',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_overhead.to_csv('evaluation/avg_overhead-unsplash_1-01_to_1-10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Print__ $\\LaTeX{}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_overhead = pd.read_csv('evaluation/avg_overhead-nodejs_1-01_to_1-10.csv')\n",
    "df_runtimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"PRP\", \"PwoD\", \"POP\", \"P-ALPaCA\", \"Padme\", \"D-ALPaCA\"]\n",
    "legend = {\n",
    "          \"PRP\": \"[line width=1pt, densely dotted, curvecolor]\", \n",
    "          \"PwoD\": \"[line width=1pt, solid, curvecolor]\", \n",
    "          \"POP\": \"[line width=1pt, dash pattern=on 1pt off 3pt on 3pt off 3pt, curvecolor]\", \n",
    "          \"P-ALPaCA\": \"[line width=1pt, densely dotted, black]\",\n",
    "          #\"Padme\": \"[line width=1pt, solid, black, mark=*]\",\n",
    "          \"Padme\": \"[scatter, only marks, black, mark=*]\",\n",
    "          \"D-ALPaCA\": \"[line width=1pt, dash pattern=on 1pt off 3pt on 3pt off 3pt, black]\"\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    df_method_temp = df_avg_overhead.loc[df_avg_overhead['Method'] == method, ['c', 'Avg Overhead']]\n",
    "    print(\"\\\\addplot \" + legend[method])\n",
    "    print(\"table {%\")\n",
    "    for row in df_method_temp.itertuples():\n",
    "        print(str(row.c) + '\\t' + str(row[2]))        \n",
    "    print(\"};\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
